{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AESB3343 - Mineral Resource Geology and Modelling\n",
    "\n",
    "\n",
    "Welcome to the second assignment of your course, the jupyter notebooks of Exploratory Geological Data Analysis and Variogram Modelling. By working through the following 24 quetions, you will exercise yourself in how to interpret data, how to manipulate them with a different perspective, and how to define variogram model.\n",
    "\n",
    "The grade scheme for this assignment is as follows:\n",
    "\n",
    "<div align='center'>\n",
    "\n",
    "| **Assignment grade scheme** | **Final Grade** |\n",
    "|:----:|:-------:|\n",
    "| 0-29 | Fail |\n",
    "| 30-38 | 5.0 |\n",
    "| 39-43 | 6.0 |\n",
    "| 44-48 | 7.0 |\n",
    "| 48-53 | 8.0 |\n",
    "| 54-59 | 9.0 |\n",
    "| 60-65 | 10.0  |\n",
    "</div>\n",
    "\n",
    "This assignment will test your systematic thinking skills and require you to fully understand the type of data you work with. Good luck!\n",
    "\n",
    "# Hand in:\n",
    "Rename this file as `Drillholes data interpretation <FIRST_LASTNAME> <STUDENTNR>.ipynb`\n",
    "\n",
    "Upload into Brightspace: before __March 27th 2024 - 23:59__\n",
    "\n",
    "We recommend you to post your questions on the __Python Practical Forum__ in the __BrightSpace__, as your friends might have the same question like you, or you might find your answer on Brightspace before asking us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab\n",
    "import itertools\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shared different tables with you on Brightspace, `assays.txt`, `lithology.txt`, `collar.txt`, and `survey.txt`. Several python libraries can be used, however, we recommend you `pandas` and `numpy` here. Notice that these packages are not mandatory to attain scores, and all other approaches and libraries are welcome to be used.\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|   1  |   read each of `txt` files separately, and store them with a prefix of `df_` each.   |  2  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  2  | Merge `df_survey` and `df_collar`, how many boreholes have `Depth` greater than 400 meters? |  1  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  3  | Merge `df_collar` and `df_assay` together, then provide mean, variance, and skewness of `CU` values at which their borehole `X` lies between 8300 and 8350, including both. |  2  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  4  | Merge `df_assay` and `df_lithology` dataframes, and provide your thought about the shape and structure of the merged file. |  2  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer Q4:\n",
    "\n",
    "**Frames intersection is empty** because there are no intersection of the frames together, which should be considered as keys. `FROM` and `TO` on both dataframes are not equal to each other, meaning that desurveying is required manually to apply for merging dataframes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  5  | Merge collar, survey, and assay dataframe together to shape a new drillholes dataframe. Name it `df_holes` |  1  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  6  | Find the average value of `CU` values on each `BHID`. Name this variable as `df_holes_avg`. Then provide a histogram of average values ( if you want, rename the column `CU` with `CU_avr` ). |  2  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  7  | By using `df_holes_avg`, create a scatter plot section of `X` and `Y` values, coloring the points with `CU_avr` values. The plot should have a legend ( scalebar is optional ) with annotations of hole names with their `BHID` for all points. Visually inspecting, how high average-grade-value boreholes are distributed on this plot? |  3  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  8  | At which borehole, the maximum value of copper can be seen? At which depth is this value observed?( lets  call this borehole hereinafter as `BH_MAX` ) |  1  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BH_MAX = # YOUR VALUE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Tough Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  9  | For `BH_MAX` borehole, make two plots of `CU` values against `FROM`, one of which should contain cumulative values. How many sudden changes ( or peaks ) of copper can you see along `FROM` interval for this borehole roughly? |  3  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the outcome of two previous questions, you have found at which borehole ( `BHID` ) and at which depth( from which `FROM` to which `TO` ), maximum copper value is detected. Assuming this value as outlier, in the following questions we are going to extend our investigation interval by 5 meters, looking more about data in the surrounding of outlier. \n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  10  | Create a new variable `df_interval` in which all boreholes included based on intervals detected as copper high value, extending Â± 5 meters. this variable will contain all copper values from all boreholes, but filtered out samples that are not fit in the new intervals margin. |  1  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Tough Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  11  | What is the average of copper per interval in `df_interval`? create a separte bar plot of average values against `FROM` and provide your thoughts about average variation inside the plot. |  4  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  12  | Using `df_interval`, Create a scatter plot ( or bar plot ) of intervals with the copper grade values. How averaged grade values are distributed along the depth? Are there any meaningful patterns in these plots?( bar chart of previous questions can also help you in your validation ) |  3  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  13  | Invesitage which drillholes are not available in `df_interval`. Can you find out what the reasons of their absense in `df_interval`? (hint: you can use `numpy.setdiff1d` or `set`) |  4  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  14  | If you are supposed to use this dataset ( `df_holes` )for kriging estimation methods ( Ordinary or Simple ), what would be your strategy in dealing with this outlier? provide your reasons with the adequate support. ( codes and plots if needed ) |  2  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following questions, you are going to take some steps further which are crucial in resource modelling; forging drillholes database by considering lithology, and performing variography on your dataset.\n",
    "\n",
    "for creating drillholes with considering lithology `LITH`, follow the steps below for better understanding as recommendation:\n",
    "1. Start by drawing the starting DataFrames on a paper with the columns and headers\n",
    "2. Following, draw the final `DataFrame` you would like to get that contains all data necessary for plotting.\n",
    "3. You could start with your `assay` dataframe. You can fill a new `LITH` column by finding from your interval the corresponding lithology from the lithology dataframe.\n",
    "4. If you have difficulties finding the lithology in an interval (some lithos present), perhaps make a new lithology called `CONTACT`...\n",
    "\n",
    "like always, do let us know if any queries.\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| # | **Very Tough Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  15  | Execute the above described assignment. The result should be a dataframe where you indicated for each `BHID` the interval `FROM` - `TO` with associated `CU` grade and `LITH` indicator. Hereinafter, we call this variable `df_holesfinal` ( you can use your own custom name if you want ). |  6  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  16  | Make a scatter plot of depth versus copper grade of samples, color the points with their associated `LITH`. Describe the depth distribution of each lithology, and support your claims with plots and codes if necessary. ( hint: you can use `violinplot` and `describe` for better understanding about depth beside the scatter plot and other techniques ) |  4  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  17  | Describe the copper concentration distribution in each lithology, along the depth, and other features you might find beneficial in your dataset ( codes and plots are welcome ) |  3  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  18  | Could you explain how the lithology was assigned for borehole BH124? |  1  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  19  | Compare copper grade distribution among lithologies with each other, and explain whether or not there are relationships between concentration of `CU` and `LITH`. You can use histograms, scatter plots, or qqplots for better demonstration. Other types of plots or statistical analysis are welcome |  3  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following questions, variogram modelling is at hand. Make sure that your drillholes dataset is still valid ( we assumed `df_holesfinal` here ), as we need this dataframe for the rest of this assignment.\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  20  | In the plot below, simply guessing, what do you think the value at (8750, 4725) would be (See the * in the plot)? |  1  |\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex;justify-content: center\">\n",
    "<img src=./Images/plotcollars.png width=500 height=500 style=\"margin: 10px 35px\">\n",
    "</div>\n",
    "\n",
    "If you cannot see the image, execute the following code to see the plot \n",
    "\n",
    "``` python\n",
    "\n",
    "df_holesfinal_avg   =   df_holesfinal.groupby('BHID')[['X','Y','CU']].mean()\n",
    "figfig = plt.figure(figsize=(8, 8))\n",
    "# axfig = figfig.gca()\n",
    "scat = plt.scatter(df_holesfinal_avg['X'], df_holesfinal_avg['Y'], s=40, c=df_holesfinal_avg['CU'], cmap='jet', alpha=0.5)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"BHs Plot section with Average Cu Grades\")\n",
    "plt.scatter(8750, 4725, c='k', marker='*', s=150)\n",
    "plt.colorbar( scat , label=\"Average Cu Grade\", shrink=1.0 )\n",
    "plt.show()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find some helper functions required for the variogram modelling with their explainations.\n",
    "\n",
    "**The semivariogram**\n",
    "\n",
    "The semivariogram encodes data about spatial variance over the region at a given distance or lag. We generally expect data points that are close together spatially to share other characteristics, and we expect points that are separated by greater distances to have lesser correlation. The semivariogram allows us to model the similarity points in a field as a function of distance.\n",
    "\n",
    "`h` is the distance specified by the user, and `z_{i}` and `z_{j}` are two points that are separated spatially by `h`. The `N(h)` term is the number of points we have that are separated by the distance `h`. The semivariogram then is the sum of squared differences between values separated by a distance `h`. In the semivariogram we are taking the squared difference between data points separated by distance `h`. We can write some functions to calculate the semivariogram at one lag, and then at multiple lags as follows.\n",
    "\n",
    "```python\n",
    "\n",
    "    \"\"\"Calculate the pairwise distance matrix. \n",
    "    Similar as scipy.squareform(scipy.pdist(xy)), but then implemented in \n",
    "    only numpy and pandas.\n",
    "    \n",
    "    Args:\n",
    "        df(DataFrame): input dataframe containing X and Y column.\n",
    "    \"\"\"\n",
    "def calc_pairwise_distance_matrix(points):\n",
    "    vert_dist = lambda A,B: ((B[0]-A[0])**2+(B[1]-A[1])**2)**(1.0/2)\n",
    "    pairwise_distance = []\n",
    "    for point in points:    \n",
    "        dist = []\n",
    "        for otherpoint in points:\n",
    "            paired_distance = vert_dist(point, otherpoint)\n",
    "            dist.append(paired_distance)  \n",
    "        pairwise_distance.append(dist)\n",
    "    return numpy.array(pairwise_distance)\n",
    "```\n",
    "\n",
    "In the following questions, variogram modelling is at hand. Make sure that your drillholes dataset is still valid, as we need this dataframe for the rest of this assignment.\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  21  | In the previous question, we defined `df_holesfinal_avg`, which represents collar of each borehole with the mean of copper grades each. Apply pariwise distance calculation function ( which is written below as well ) on `df_holesfinal_avg`. By excluding zero values, what are the minimum, mean and maximum distances between all points? |  3  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These minimum and maximum value are useful, because we can determine the lag range with this (over which range points may potentially correlate with each other). In addition, we will use this to determine the stepsize we need for this lag range.\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| # | **Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  22  | Make a histogram plot of pairwise distances. Given the statistical properties of this distribution, what lag distances ( `stepsize` * `numsteps` ) would you recommend for calculating experimental variogram? ( do not forget the main assumptions of variography ðŸ˜Š ) |  3  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! after defining your lags collection, we need to calculate the experimental variogram and fit a model to it. Codes below demonstrates the basics of variography in python ( for more a bit efficient and advanced calculation tecniques, please visit [here](https://github.com/kiarash13p/Mineral-Resource-Geology-and-Modelling/blob/main/Kriging%20Solution.ipynb) ). You can use your own functions to calculate variograms.\n",
    "\n",
    "``` python\n",
    "def semivariogram_h(P, variable, h, stepsize):\n",
    "    \"\"\"\n",
    "    Experimental semivariogram for a single lag\n",
    "\n",
    "    Args:\n",
    "        P(array): input points.\n",
    "        variable(array): variable to be modelled.\n",
    "        h(int): the defined lag to calculate distances at.\n",
    "        stepsize(int): stepsize uses between the different lags.\n",
    "        \n",
    "    Output:\n",
    "        svh(array): semivariance value at lag h.\n",
    "    \"\"\"\n",
    "    # Calculate the pairwise distance\n",
    "    pairwise_distances = calc_pairwise_distance_matrix(P)\n",
    "    N = pairwise_distances.shape[0]\n",
    "    Z = list()\n",
    "    for i in range(N):\n",
    "        for j in range(i+1,N):\n",
    "            if(pairwise_distances[i,j] >= h-stepsize )and(pairwise_distances[i,j] <= h+stepsize):\n",
    "                Z.append((variable[i] - variable[j])**2.0)\n",
    "    svh = numpy.sum( Z ) / (2.0 * len( Z ))\n",
    "    return svh\n",
    "\n",
    "def semivariogram(P, variable, hs, stepsize):\n",
    "    \"\"\"\n",
    "    Experimental variogram for a collection of lags.\n",
    "    \n",
    "    Args:\n",
    "        P(array): input points.\n",
    "        variable(array): variable to be modelled.\n",
    "        hs(array): the defined lags to calculate distances at.\n",
    "        stepsize(int): stepsize uses between the different lags.\n",
    "        \n",
    "    Output:\n",
    "        sv(array): Empirical semivariogram values\n",
    "    \"\"\"\n",
    "    sv = list()\n",
    "    for h in hs:\n",
    "        sv.append(semivariogram_h(P, variable, h, stepsize))\n",
    "    sv = [[hs[i], sv[i]] for i in range( len( hs ) ) if sv[i] > 0]\n",
    "    return numpy.array(sv).T\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Tough Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  23  | Calculate variogram (gamma) values of each lag you decided already, then make a plot of calculated variograms versus lags.( you may need to redo this step and previous one multiple times to find the best fit, and do not forget geostatistical assumptions and variance of your data ðŸ˜Š ). |  6  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For kriging it is required that this empirical ( experimental ) variogram is replaced with a modelled variogram model. The reason for this is that the kriging algorithm will need access to variogram values for lag distances other than those used in the empirical one. \n",
    "\n",
    "We will simply use a spherical variogram model for fitting, given the parameters you decided already. ( for more a bit efficient and advanced calculation tecniques, please visit [here](https://github.com/kiarash13p/Mineral-Resource-Geology-and-Modelling/blob/main/Kriging%20Solution.ipynb) )\n",
    "\n",
    "``` python \n",
    "'''\n",
    "def spherical(h, a, C0):\n",
    "    #Spherical model of the semivariogram\n",
    "    \"\"\"\n",
    "    Spherical model of the semivariogram.\n",
    "    \n",
    "    Args:\n",
    "        h(float/int): the defined lag to calculate distances at.\n",
    "        a(float/int): range value.\n",
    "        C0(float/int): the sill value.\n",
    "    \n",
    "    \"\"\"\n",
    "    # if h is a single digit\n",
    "    if type(h) == np.float64 or type(h) == np.int64:\n",
    "        # calculate the spherical function\n",
    "        if h <= a:\n",
    "            return C0*( 1.5*h/a - 0.5*(h/a)**3.0 )\n",
    "        else:\n",
    "            return C0\n",
    "    # if h is an iterable\n",
    "    else:\n",
    "        # calcualte the spherical function for all elements\n",
    "        a = np.ones( h.size ) * a\n",
    "        C0 = np.ones( h.size ) * C0\n",
    "        return list(map( spherical, h, a, C0 ))\n",
    "'''\n",
    "    \n",
    "# NOTE NOTE NOTE #    \n",
    "# Please use the below implementation of the spherical function if the below function gives problems.\n",
    "\n",
    "def spherical(h, a, nugget , sill ):\n",
    "    # calculate the spherical function\n",
    "    if h <= a:\n",
    "         return nugget + (sill-nugget)*( 1.5*h/a - 0.5*(h/a)**3.0 )\n",
    "    else:\n",
    "         return sill\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "\n",
    "| # | **Tough Question** | Score |\n",
    "|:-:|:-:|:-:|\n",
    "|  24  | Using the function above ( or your own custom function ), fit the best variogram model on to your experimental one. What would be your recommendation of best values for major settings of variogram model such as `nugget`, `sill`, and `range_` for model fitting? Provide some of your thoughts and interpretations you made towards these values. |  4  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nugget = # YOUR CHOICE\n",
    "sill = # YOUR CHOICE\n",
    "range_ = # YOUR CHOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
